{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying and Natural Language Processing with Yelp Reviews Data\n",
    "#### W207 Section 3, Group - <span style=\"color:orange\"><strong>C</strong></span>olors\n",
    "#### Summer, 2018\n",
    "#### Team members:\n",
    "- Chandra Sekar, chandra-sekar@ischool.berkeley.edu\n",
    "- Guangyu (Gary) Pei, guangyu.pei@ischool.berkeley.edu\n",
    "- Jooyeon (Irene) Seo, jooyeon@ischool.berkeley.edu\n",
    "- Sijie (Anne) Yu, syu.anne@berkeley.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version used: 3.6.5 |Anaconda custom (64-bit)| (default, Mar 29 2018, 13:14:23) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Numpy version used: 1.14.2\n",
      "sklearn version used: 0.19.1\n"
     ]
    }
   ],
   "source": [
    "# General libraries.\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# keras package for neural networks.\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# Config Jupyter session\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)\n",
    "\n",
    "# Global configurations\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "# Config system logs\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                   format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# print versions\n",
    "print(\"Python version used:\", sys.version)\n",
    "print(\"Numpy version used:\", np.__version__)\n",
    "print(\"sklearn version used:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goals\n",
    "Our projectâ€™s primary concept is to utilize Yelp data (from kaggle) to rate new business. That is, we are going to get Yelp user review data, use review texts to predict review is **positive** or **negative**. When people talk about a new business, we can capture their words, fit into the model, then predict its rating, sort of understand its quality and potential.\n",
    "\n",
    "#### The Yelp Review Dataset\n",
    "We write a shell [script](https://github.com/annesjyu/m207_summer_2018) to select $10,000$ reviews for training, testing and dev respectively, each set consisting in 50% negative and 50% positive reviews. We keep only review text and stars columns, then binarize stars into target label: \n",
    "- if stars >= $3.0$, review is *positive*\n",
    "- otherwise, it's *negative*.\n",
    "\n",
    "The following code will load the dataset and split it into $3$ sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data dim:  (29701, 2)\n",
      "train data size:  12000\n",
      "test data size:  10000\n",
      "dev data size:  7700\n",
      "________________________________________________________________________________\n",
      "Training examples:\n",
      " ['Orange Blossom Beer is the best  However atmosphere and Service (Female Bartender/Server) were really bad... Go to Chevron get a growler  go home and Enjoy!!! '\n",
      " \"Tried this place one time shortly after they opened.   I wasn't really impressed with their food. The place did look neat and clean and the staff was very friendly.  Although I wasn't impressed with my one visit based on the customer service I'll probably try it again at some point. \"]\n",
      "[0 1]\n",
      "________________________________________________________________________________\n",
      "Testing examples:\n",
      " ['Not worth going to. I ordered a ramen and the chicken was very dry and over done  the soup was way too salty and tasted very artificial as well. Definitely way better ramen shops in the gta. The chicken bao was absolutely horrible because  1. It was way too spicy  and 2. Way too dry. It burnt my mouth and stomach the whole night. '\n",
      " 'Service was horrible! Some European lady with an accent came to take our order and right in the middle of my order she walked away and helped someone else! I called her back to ask her if we could finish our order. She rudely complied.. I was sitting on the far left of the bar and I could clearly see the kitchen. The server was sitting on a keg taking off her shoes and picking dirt from in between her toes.. I then saw her place carrots and celery with her dirty foot fingers into our plates! DISGUSTING! Food was alright. Will not be coming here again I DO NOT RECOMMEND THIS PLACE ']\n",
      "[0 0]\n",
      "________________________________________________________________________________\n",
      "Dev examples:\n",
      " ['Absolute ripoff and terrible customer service! I went here for a bachelor party as I was told it was an upscale gentlemen\\'s club. After the $50 cover charge we found the place went downhill from there. We had one of the entertainers lie to us in order to go into the so called VIP area with a promise of 1 full hour of performances and 10 drinks included for $450. Then we were hustled further by being charged a 15% service fee and a 20% gratuity at the VIP entry in advanced \"\"before\"\" even being seated. What a joke!!!! Once in there we ordered a round of 3 drinks and it came out to $80. We challenged this charge stating we were told the first 10 drinks would be included! A lie from our entertainer Mariah!!! After performing for about 15-20 minutes Mariah said she was done. What about the hour that was promised? She then stated it was only half an hour and it was \"\"her bad\"\". We were very upset at this point because we were basically robbed of $700 over the course of 20 minutes! I then called Nicole later that day to dispute the charges  her response was that we should not have trusted anything that their entertainers said or promised. She said that they were independent contractors and they could say whatever they want. Even though they work under Crazyhorse 3\\'s roof. I was like really? I couldn\\'t believe it!!! Then she had our VIP host Darius call me later that day. Another total waste of time!!! He offered me a 200 gift card to use at the club. Basically an admission of guilt. Why would he offer us a $200 gift card if we weren\\'t lied to? Plus that\\'s not even close to the $700 we were hustled out of. I made it abundantly clear to him that I had no desire to go back to a place that rips people off. I asked for a full refund that I felt I was entitled to. I even told them to keep the $80 for the drinks I was misrepresented about. He promised that he would talk to his boss to get back to me within 24 hours. Another Crazyhorse 3 lie. It\\'s been almost 2 weeks and what a surprise  no response from Darius. I\\'ve left him three voicemails and three text messages with not as much as one response. This place is a rip off and the customer service is a joke. Don\\'t waste your time  patience  or money. I should\\'ve read their yelp reviews before I went. Browse through and you will see that they consistently rip people off. Pretty awful business practices. '\n",
      " 'Recommend that you stay somewhere else! Older property. Most of the staff just going through the motions. Bed was too firm for us. ']\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "with np.warnings.catch_warnings():\n",
    "    # There are some bad data, we just dont want to see a lot of warning messages\n",
    "    np.warnings.filterwarnings('ignore', r'Some errors were detected')\n",
    "    data = np.genfromtxt('data.csv',dtype='str', delimiter='|', skip_header=1, \n",
    "                         usecols = (0,1), invalid_raise=False, loose=True)\n",
    "\n",
    "    print (\"Full data dim: \", data.shape)\n",
    "    \n",
    "    # Shuffle the data, each dataset will have roughly the same number of examples for each label.\n",
    "    shuffle = np.random.permutation(np.arange(data.shape[0]))\n",
    "    X, Y = data[shuffle, 0], data[shuffle, 1]    \n",
    "    \n",
    "    train_data, train_labels = X[0:12000], Y[:12000].astype(np.int)\n",
    "    test_data, test_labels = X[12000:22000], Y[12000:22000].astype(np.int)\n",
    "    dev_data, dev_labels = X[22000:-1], Y[22000:-1].astype(np.int)\n",
    "\n",
    "    NUM_OF_TRAINING_DATA = len(train_data)\n",
    "    NUM_OF_TESTING_DATA = len(test_data)\n",
    "    NUM_OF_DEV_DATA = len(dev_data)\n",
    "\n",
    "    print ('train data size: ', NUM_OF_TRAINING_DATA)\n",
    "    print ('test data size: ', NUM_OF_TESTING_DATA)\n",
    "    print ('dev data size: ', NUM_OF_DEV_DATA)\n",
    "    print ('_'*80)\n",
    "    print ('Training examples:\\n', train_data[0:2])\n",
    "    print (train_labels[0:2])\n",
    "    print ('_'*80)\n",
    "    print ('Testing examples:\\n', test_data[0:2])\n",
    "    print (test_labels[0:2])\n",
    "    print ('_'*80)\n",
    "    print ('Dev examples:\\n', dev_data[0:2])\n",
    "    print (dev_labels[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze train, dev and test datasets to find out data distributions. Ideally we want to have 50% examples for either label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive train data:  6050 , negative train data:  5950\n",
      "positive test data:  5000 , negative test data:  5000\n",
      "positive dev data:  3812 , negative dev data:  3888\n"
     ]
    }
   ],
   "source": [
    "print ('positive train data: ', len(np.where(train_labels==1)[0]), \n",
    "       ', negative train data: ', len(np.where(train_labels==0)[0]))\n",
    "print ('positive test data: ', len(np.where(test_labels==1)[0]), \n",
    "       ', negative test data: ', len(np.where(test_labels==0)[0]))\n",
    "print ('positive dev data: ', len(np.where(dev_labels==1)[0]), \n",
    "       ', negative dev data: ', len(np.where(dev_labels==0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fnm = \"data_restaurants_reviews_30_to_200_stars_1_5\", seed = 1234,\n",
    "              train_frac= 0.8, dev_size = 1000):\n",
    "    data = pd.read_pickle(fnm)\n",
    "    np.random.seed(seed)\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    print (\"Total data size:\", data.shape[0])\n",
    "    traing_size = int(np.floor(data.shape[0]*train_frac))\n",
    "    test_size = int(np.floor(data.shape[0]*(1.0-train_frac))) - dev_size\n",
    "    train_data, train_labels = data.X[0:traing_size], data.Y[0:traing_size]\n",
    "    test_data, test_labels = data.X[traing_size:(traing_size+test_size)], data.Y[traing_size:(traing_size+test_size)]\n",
    "    dev_data, dev_labels = data.X[(traing_size+test_size):-1], data.Y[(traing_size+test_size):-1]\n",
    "    return train_data, train_labels, test_data, test_labels, dev_data, dev_labels\n",
    "    \n",
    "\n",
    "train_data, train_labels, test_data, test_labels, dev_data, dev_labels = load_data()\n",
    "\n",
    "print ('train data size: ', train_data.shape)\n",
    "print ('test data size: ', test_data.shape)\n",
    "print ('dev data size: ', dev_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural Language Processing on Review Texts\n",
    "\n",
    "We will create a doc-term matrix from review texts, so that classifiers can use it as an feature. There are a couple of steps of doing it. \n",
    "- First of all we will conduct Natural Language Processing with customized stemmer, stop words etc. \n",
    "- Secondly we will use Logistic Regression + L1 Regulization to reduce non-important terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in  6.771087646484375e-05  s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "categories = ['Positive reviews', 'Negative reviews']\n",
    "\n",
    "def NLP_text(verbose):\n",
    "    \"\"\"The function will take a vector of texts and create a Doc-Term Matrix.\n",
    "    Input:\n",
    "        verbose: if true, will print debug info.\n",
    "    Output:\n",
    "        a customized vectorizer object.\n",
    "    \"\"\"    \n",
    "    def better_tokenizer(s):\n",
    "        tokens = TfidfVectorizer().build_tokenizer()(s)\n",
    "        # create English stop words list\n",
    "        stop_words = get_stop_words('en')\n",
    "        \n",
    "        # Create p_stemmer of class PorterStemmer\n",
    "        p_stemmer = PorterStemmer()\n",
    "        \n",
    "        # We compute the average length of original dictionary, which is 6.7\n",
    "        # then ignore extremly short and long words, like more than 6.7/2 and 6.7*2.\n",
    "        WORD_LEN = 6.7\n",
    "        \n",
    "        return [p_stemmer.stem(t) for t in tokens if len(t) >= WORD_LEN/2 \n",
    "                and len(t) <= WORD_LEN*2 and t not in stop_words]\n",
    "           \n",
    "    shuffle = np.random.permutation(train_data.shape[0])\n",
    "    X, Y = train_data[shuffle], train_labels[shuffle]\n",
    "    TUNE_DATA_SIZE = int(len(train_data)/6)\n",
    "    data = X[0:TUNE_DATA_SIZE]\n",
    "    labels = Y[0:TUNE_DATA_SIZE]\n",
    "    \n",
    "    vect1 = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,1), min_df=2, \n",
    "                            stop_words='english', use_idf=False, sublinear_tf=True, \n",
    "                            max_features=10000, tokenizer=better_tokenizer)\n",
    "    \n",
    "    data_dtm = vect1.fit_transform(data)\n",
    "    features = vect1.get_feature_names()\n",
    "    print ('num of original terms: ', len(features))\n",
    "\n",
    "    # Reduce terms using Logistic Regression + L1 regulirization\n",
    "    # If the the term has a non-zero weight we will keep it, otherwise, exclude it from DTM.\n",
    "    Logistic_Regression_optimal_C = 10\n",
    "    lg = LogisticRegression(penalty=\"l1\", tol=0.01, C=Logistic_Regression_optimal_C)\n",
    "    lg.fit(data_dtm, labels)\n",
    "    print ('dim of coef matrix: ', lg.coef_.shape)\n",
    "    #print ('accuracy: ', metrics.accuracy_score(labels, lg.predict(test_data, test_labels)))\n",
    "    \n",
    "    nonzero_features_indices = np.array(np.nonzero(lg.coef_[0])[0])\n",
    "    print ('num of nonzero terms: ', nonzero_features_indices.shape)\n",
    "    \n",
    "    reduced_terms = [features[int(w)] for w in nonzero_features_indices]\n",
    "    if verbose:\n",
    "        print ('non-zero terms:\\n%s' %reduced_terms)\n",
    "    \n",
    "    vect2 = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,1), min_df=2, \n",
    "                            use_idf=False, sublinear_tf=True, \n",
    "                            tokenizer=better_tokenizer, \n",
    "                            vocabulary=reduced_terms)\n",
    "    \n",
    "    return vect2\n",
    "\n",
    "# Get the customized and improved vectorizer\n",
    "verbose = False\n",
    "start = time.time()\n",
    "#better_vect = NLP_text(verbose)\n",
    "print ('done in ', time.time() - start, ' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a baseline using default CountVectorizer and NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 5402)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.87      0.81      3422\n",
      "          1       0.88      0.78      0.83      4278\n",
      "\n",
      "avg / total       0.83      0.82      0.82      7700\n",
      "\n",
      "top 100 terms:\n",
      " ['took', 'vegas', 'selection', 'things', 'table', 'stars', 'worth', 'sweet', 'bad', 'different', 'work', 'overall', 'perfect', 'salad', 'quite', 'drinks', 'dinner', 'home', 'hot', 'favorite', 'need', 'long', 'places', 'excellent', 'meal', 'thing', 'big', 'clean', 'feel', 'price', 'location', 'happy', 'wasn', 'awesome', 'cheese', 'lunch', 'eat', 'super', 'tried', 'looking', 'prices', 'sauce', 'times', 'new', 'lot', 'night', 'say', 'want', 'bit', 'area', 'small', 'wait', 'sure', 'bar', 'day', 'll', 'experience', 'recommend', 'fresh', 'chicken', 'way', 'amazing', 'went', 'going', 'know', 'better', 'right', 'think', 'order', 'people', 'didn', 'ordered', 'restaurant', 'did', 'make', 'menu', 'came', 'come', 'staff', 'pretty', 'got', 'delicious', 'try', 'little', 'definitely', 'don', 'best', 'friendly', 'love', 'nice', 've', 'really', 'time', 'just', 'like', 'service', 'food', 'great', 'place', 'good']\n",
      "________________________________________________________________________________\n",
      "lest important 100 terms:\n",
      " ['units', 'blamed', 'blatantly', 'questioned', 'belongings', 'shrugged', 'canceled', 'nur', 'incompetent', 'incorrectly', 'offensive', 'rudely', 'compensation', 'liar', 'arrogant', 'arguing', 'faulty', 'denied', 'dishonest', 'appalled', 'crooks', 'insult', 'dispute', 'threatened', 'overcharged', 'threatening', 'noch', 'acknowledge', 'acknowledgement', 'yell', 'stinks', 'bbb', 'refusing', 'heater', 'redeeming', 'refunded', 'antibiotics', 'odor', 'owed', 'stolen', 'auf', 'touched', 'atrocious', 'sehr', 'flagged', 'mistakes', 'billing', 'dept', 'dem', 'interrupted', 'dass', 'unwilling', 'cuticles', 'smh', 'disconnected', 'disgusted', 'responsibility', 'vacuum', 'valuable', 'inspector', 'lease', 'confronted', 'lied', 'rudeness', 'proceed', 'lousy', 'von', 'elderly', 'sarcastic', 'subpar', 'cable', 'wasting', 'expired', 'bleeding', 'hier', '700', 'rudest', 'reads', 'backing', 'thousands', 'nicht', 'legal', 'inconvenient', 'tostada', 'prove', 'nerve', 'unacceptable', 'operating', 'inspect', 'vomit', 'assigned', 'opinions', 'bait', 'pages', 'failure', 'posting', 'repeated', 'cigarettes', 'als', 'claimed']\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "v = CountVectorizer(strip_accents='ascii', stop_words='english', min_df=0.001)\n",
    "train_dtm = v.fit_transform(train_data)\n",
    "print (train_dtm.shape)\n",
    "\n",
    "bnb = BernoulliNB(alpha=0.01)\n",
    "bnb.fit(train_dtm, train_labels)\n",
    "predicted = bnb.predict(v.transform(dev_data))\n",
    "\n",
    "print (classification_report(predicted, dev_labels))\n",
    "\n",
    "terms = v.get_feature_names()\n",
    "top100 = np.argsort(bnb.coef_[0])[-100:]\n",
    "print ('top 100 terms:\\n',[terms[int(w)] for w in top100])\n",
    "print ('_'*80)\n",
    "bottom100 = np.argsort(bnb.coef_[0])[:100]\n",
    "print ('lest important 100 terms:\\n',[terms[int(w)] for w in bottom100])\n",
    "print ('_'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression Model\n",
    "\n",
    "In this section, we will train Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yelp_review_logistic_regression_model(train_data = train_data,\n",
    "                                          train_labels = train_labels,\n",
    "                                          test_data = dev_data,\n",
    "                                          test_labels = dev_labels,\n",
    "                                          seed = 1234):\n",
    "    # Keep this random seed so that this function is reproducible.\n",
    "    np.random.seed(seed)\n",
    "    count_vectorizer = CountVectorizer(strip_accents='ascii', stop_words='english', min_df=0.001)\n",
    "    dtm_train = count_vectorizer.fit_transform(train_data)\n",
    "    # compare the number of nonzero weights from l1 and l2\n",
    "    logistic_l1 = LogisticRegression(penalty=\"l1\")\n",
    "    logistic_l1.fit(dtm_train, train_labels)\n",
    "    # Method 1 using np.nonzero\n",
    "    print(\"Number of nonzero weights with l1 penalty is {:d}.\".format(len(set((np.nonzero(logistic_l1.coef_))[1]))))\n",
    "    logistic_l2 = LogisticRegression(penalty=\"l2\")\n",
    "    logistic_l2.fit(dtm_train, train_labels)\n",
    "    print(\"Number of nonzero weights with l2 penalty is {:d}.\".format(len(set((np.nonzero(logistic_l2.coef_))[1]))))\n",
    "    \n",
    "    # vary C parameters and plot the graph\n",
    "    vocabsizes = []\n",
    "    l1_cs = []\n",
    "    f1_scores = []\n",
    "    for i in np.logspace(-3, 2, num=20):\n",
    "        logistic_l1 = LogisticRegression(penalty=\"l1\", tol=0.01, C=i)\n",
    "        logistic_l1.fit(dtm_train, train_labels)\n",
    "        # features that have at least one non-zero weights under l1 penalty\n",
    "        l1_nonzero_vocab = np.array(count_vectorizer.get_feature_names())[list(set((np.nonzero(logistic_l1.coef_))[1]))]\n",
    "        vocabsizes.append(len(l1_nonzero_vocab))\n",
    "        l1_cs.append(i)\n",
    "        # using vocabulary based on non-zero weights from l1 penalty logistic regression results\n",
    "        vectorizer_with_reduced_vocab = CountVectorizer(vocabulary=l1_nonzero_vocab)\n",
    "        dtm_with_reduced_vocab = vectorizer_with_reduced_vocab.fit_transform(train_data)\n",
    "        dtm_test_with_reduced_vocab = vectorizer_with_reduced_vocab.transform(test_data)\n",
    "        # fit logistic regression with penalty l2\n",
    "        logistic_l2_retrain = LogisticRegression(penalty=\"l2\")\n",
    "        logistic_l2_retrain.fit(dtm_with_reduced_vocab, train_labels)\n",
    "        f1_scores.append(metrics.f1_score(test_labels,\n",
    "                                          logistic_l2_retrain.predict(dtm_test_with_reduced_vocab),\n",
    "                                          average = 'macro'))\n",
    "    \n",
    "    # plot the results\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(vocabsizes, f1_scores, 'bo', markersize=15)\n",
    "    plt.title('F1 scores of the re-trained model with l2 vs. the vocabulary size based on l1')\n",
    "    plt.xlabel('Vocabulary size')\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.rcParams[\"font.size\"] = 12\n",
    "    \n",
    "    print(\"Best F1 score with L2 regularization is {:.2f}.\\nThe best F1 score is achieved by using the vocabulary size {:d} determined by L1 regularization with C parameter {:.5f}\"\\\n",
    "          .format(np.max(f1_scores),vocabsizes[np.argmax(f1_scores)],l1_cs[np.argmax(f1_scores)]))\n",
    "\n",
    "yelp_review_logistic_regression_model()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Networks\n",
    "\n",
    "In this section, we will train Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 7700 samples\n",
      "Epoch 1/20\n",
      "12000/12000 [==============================] - 2s 127us/step - loss: 0.5691 - acc: 0.7667 - val_loss: 0.4642 - val_acc: 0.8614\n",
      "Epoch 2/20\n",
      "12000/12000 [==============================] - 1s 88us/step - loss: 0.3900 - acc: 0.8892 - val_loss: 0.3757 - val_acc: 0.8775\n",
      "Epoch 3/20\n",
      "12000/12000 [==============================] - 1s 86us/step - loss: 0.2979 - acc: 0.9118 - val_loss: 0.3353 - val_acc: 0.8816\n",
      "Epoch 4/20\n",
      "12000/12000 [==============================] - 1s 85us/step - loss: 0.2417 - acc: 0.9243 - val_loss: 0.3184 - val_acc: 0.8805\n",
      "Epoch 5/20\n",
      "12000/12000 [==============================] - 1s 86us/step - loss: 0.2030 - acc: 0.9359 - val_loss: 0.3169 - val_acc: 0.8801\n",
      "Epoch 6/20\n",
      "12000/12000 [==============================] - 1s 85us/step - loss: 0.1737 - acc: 0.9450 - val_loss: 0.3239 - val_acc: 0.8782\n",
      "Epoch 7/20\n",
      "12000/12000 [==============================] - 1s 86us/step - loss: 0.1502 - acc: 0.9504 - val_loss: 0.3371 - val_acc: 0.8765\n",
      "Epoch 8/20\n",
      "12000/12000 [==============================] - 1s 95us/step - loss: 0.1305 - acc: 0.9577 - val_loss: 0.3529 - val_acc: 0.8753\n",
      "Epoch 9/20\n",
      "12000/12000 [==============================] - 1s 104us/step - loss: 0.1132 - acc: 0.9638 - val_loss: 0.3738 - val_acc: 0.8718\n",
      "Epoch 10/20\n",
      "12000/12000 [==============================] - 1s 90us/step - loss: 0.0983 - acc: 0.9695 - val_loss: 0.4006 - val_acc: 0.8696\n",
      "Epoch 11/20\n",
      "12000/12000 [==============================] - 1s 92us/step - loss: 0.0847 - acc: 0.9752 - val_loss: 0.4203 - val_acc: 0.8700\n",
      "Epoch 12/20\n",
      "12000/12000 [==============================] - 1s 86us/step - loss: 0.0729 - acc: 0.9794 - val_loss: 0.4465 - val_acc: 0.8677\n",
      "Epoch 13/20\n",
      "12000/12000 [==============================] - 1s 88us/step - loss: 0.0621 - acc: 0.9828 - val_loss: 0.4803 - val_acc: 0.8665\n",
      "Epoch 14/20\n",
      "12000/12000 [==============================] - 1s 89us/step - loss: 0.0530 - acc: 0.9863 - val_loss: 0.5158 - val_acc: 0.8642\n",
      "Epoch 15/20\n",
      "12000/12000 [==============================] - 1s 92us/step - loss: 0.0444 - acc: 0.9885 - val_loss: 0.5485 - val_acc: 0.8625\n",
      "Epoch 16/20\n",
      "12000/12000 [==============================] - 1s 91us/step - loss: 0.0368 - acc: 0.9907 - val_loss: 0.5856 - val_acc: 0.8597\n",
      "Epoch 17/20\n",
      "12000/12000 [==============================] - 1s 89us/step - loss: 0.0315 - acc: 0.9917 - val_loss: 0.6246 - val_acc: 0.8577\n",
      "Epoch 18/20\n",
      "12000/12000 [==============================] - 1s 87us/step - loss: 0.0251 - acc: 0.9946 - val_loss: 0.6604 - val_acc: 0.8558\n",
      "Epoch 19/20\n",
      "12000/12000 [==============================] - 1s 91us/step - loss: 0.0208 - acc: 0.9958 - val_loss: 0.6917 - val_acc: 0.8553\n",
      "Epoch 20/20\n",
      "12000/12000 [==============================] - 1s 88us/step - loss: 0.0167 - acc: 0.9965 - val_loss: 0.7488 - val_acc: 0.8523\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def yelp_review_neural_networks():\n",
    "\n",
    "    count_vectorizer = CountVectorizer(strip_accents='ascii', stop_words='english', min_df=0.001)\n",
    "    dtm_train = count_vectorizer.fit_transform(train_data)\n",
    "    dtm_dev = count_vectorizer.transform(dev_data)\n",
    "\n",
    "    # Building our model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', input_shape=(dtm_train.shape[1],)))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    # Use binary_crossentropy loss function because our model outputs probabilities\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Validate our model with dev dataset\n",
    "    history = model.fit(dtm_train, train_labels, epochs=20, batch_size=512, validation_data=(dtm_dev, dev_labels))\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    # Plot training and validation loss\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    ax.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    ax.set_title('Training and validation loss')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    \n",
    "    # Plot training and validation accuracy\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    ax2.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    ax2.set_title('Training and validation accuracy')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    \n",
    "yelp_review_neural_networks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a clear minimum in validation loss function after 4th epoch, and maximum in validation accuracy at 4th epoch. We'll fit the model with 4 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "12000/12000 [==============================] - 1s 106us/step - loss: 0.5819 - acc: 0.7881\n",
      "Epoch 2/4\n",
      "12000/12000 [==============================] - 1s 69us/step - loss: 0.4065 - acc: 0.8914\n",
      "Epoch 3/4\n",
      "12000/12000 [==============================] - 1s 64us/step - loss: 0.3139 - acc: 0.9107\n",
      "Epoch 4/4\n",
      "12000/12000 [==============================] - 1s 61us/step - loss: 0.2552 - acc: 0.9232\n",
      "7700/7700 [==============================] - 1s 92us/step\n",
      "Accuracy of Neural Network classifier is 0.88\n"
     ]
    }
   ],
   "source": [
    "def yelp_review_neural_networks():\n",
    "\n",
    "    count_vectorizer = CountVectorizer(strip_accents='ascii', stop_words='english', min_df=0.001)\n",
    "    dtm_train = count_vectorizer.fit_transform(train_data)\n",
    "    dtm_dev = count_vectorizer.transform(dev_data)\n",
    "    dtm_test = count_vectorizer.transform(test_data)\n",
    "\n",
    "    # 1) Building our model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', input_shape=(dtm_train.shape[1],)))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Use binary_crossentropy loss function because our model outputs probabilities\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(dtm_train, train_labels, epochs=4, batch_size=512)\n",
    "    results = model.evaluate(dtm_dev, dev_labels)\n",
    "    print(\"Accuracy of Neural Network classifier is\", \"{:.2f}\".format(results[1]))\n",
    "\n",
    "yelp_review_neural_networks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Exploratory Data Analysis\n",
    "\n",
    "In this section, we present the Exploratory Data Analysis (EDA) for the Yelp review data set. The goals of EDA are: (1) understand the dataset characteristics; (2) identify the relationship between Yelp ratings and business quality such that meanful and practical supervised machine learning data set is constructed.\n",
    "\n",
    "#### Load the raw data set into Pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "business=pd.read_csv(\"yelp_dataset/yelp_business.csv\")\n",
    "business_attributes=pd.read_csv(\"yelp_dataset/yelp_business_attributes.csv\")\n",
    "business_hours=pd.read_csv(\"yelp_dataset/yelp_business_hours.csv\")\n",
    "check_in=pd.read_csv(\"yelp_dataset/yelp_checkin.csv\")\n",
    "reviews=pd.read_csv(\"yelp_dataset/yelp_review.csv\", nrows=17746270)\n",
    "tip=pd.read_csv(\"yelp_dataset/yelp_tip.csv\")\n",
    "user=pd.read_csv(\"yelp_dataset/yelp_user.csv\")\n",
    "end_time=time.time()\n",
    "print(\"Reading all cvs files took \",end_time-start_time,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of reviews {:d}\".format(reviews.shape[0]))\n",
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of business {:d}.\".format(business.shape[0]))\n",
    "business.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data characteristics\n",
    "import seaborn as sns \n",
    "review_stars = reviews['stars'].value_counts().sort_index()\n",
    "plt.figure(figsize=(8,4))\n",
    "ax= sns.barplot(review_stars.index, review_stars.values, alpha=0.8)\n",
    "plt.title(\"Star Rating Distribution\")\n",
    "plt.ylabel('# of reviews', fontsize=12)\n",
    "plt.xlabel('Star Ratings ', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Yelp review star ratings are clearly not uniformly distributed. The reviews with 5 stars dominates among all reviews (more than 2 millions 5-star reviews).\n",
    "\n",
    "In the following, let us look at the distribution of business categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.DataFrame(' '.join(business['categories']).split(';'),columns=['category'])\\\n",
    "            .category.value_counts().sort_values(ascending=False)\n",
    "print(\"There are \",len(categories),\" categories of Businesses in Yelp.\")\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "ax = sns.barplot(categories[0:20].index, categories[0:20].values, alpha=0.8)\n",
    "plt.title(\"Top 20 categories\",fontsize=25)\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45)\n",
    "plt.ylabel('# businesses', fontsize=12)\n",
    "plt.xlabel('Category', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure shows that restaurant type is the top one business category. Clearly, it is hard to compare business from different categories. We can focus on restaurants since it is the most common business type on Yelp. In the following, we will investigate the number of reviews distritution for each restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_review_cnt = business.loc[(business['categories'].str.lower().str.contains('restaurant'))]['review_count']\n",
    "print(restaurant_review_cnt.describe())\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.distplot(restaurant_review_cnt)\n",
    "plt.ylabel('Distribution', fontsize=12)\n",
    "plt.xlabel('Review count', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution and statistics show that 50% restaurants received $\\le$ 18 reviews. The distribution is right skewed. Restaurants with small number of reviews are more likely biased. Based on the above distribution, we zoom in restaurants with 30 - 200 reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restauntants_with_30_to_200_reviews = business.loc[(business['review_count'].isin(range(30,201))) & (business['categories'].str.lower().str.contains('restaurant'))]\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.distplot(restauntants_with_30_to_200_reviews['review_count'], kde=False, rug=True, bins=50)\n",
    "plt.ylabel('Number of restaurants', fontsize=12)\n",
    "plt.xlabel('Review count', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_merged_with_restauntants_with_30_to_200_reviews = pd.merge(reviews, restauntants_with_30_to_200_reviews, how = 'right', on = 'business_id')\n",
    "print('Total number of reviews for restaunts that have 30 to 200 reviews:', reviews_merged_with_restauntants_with_30_to_200_reviews.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have more than 1.3 million reviews that were written for restaurants. Each of these restaurants has number of reviews between 30 to 200. In the following, we plot the number of reviews for each star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reviews_merged_with_restauntants_with_30_to_200_reviews['stars_x'].value_counts().sort_index()\n",
    "plt.figure(figsize=(8,4))\n",
    "ax= sns.barplot(x.index, x.values, alpha=0.8)\n",
    "plt.title(\"Star rating counts for restaurants with 30-200 reviews\")\n",
    "plt.ylabel('# of reviews', fontsize=12)\n",
    "plt.xlabel('Star ratings ', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of reviews with 1 star rating: \", reviews_merged_with_restauntants_with_30_to_200_reviews.loc[reviews_merged_with_restauntants_with_30_to_200_reviews['stars_x'] <2].shape[0])\n",
    "print(\"Number of reviews with 5 star rating: \", reviews_merged_with_restauntants_with_30_to_200_reviews.loc[reviews_merged_with_restauntants_with_30_to_200_reviews['stars_x'] >4].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution is very similar to ratings distribution we plotted earlier for the full data set. In another words, after we filtered the data set with business category restaurants and number of reviews for each restaurant, the star rating distribution remains the same. In the following, we randomly select 15000 from reviews with rating 1 (less than 10% of all reviews with 1 stars) and 15000 reviews with rating 5 (about 3% of total 5 star reviews). We use this random sampled data to explore the characteritics of the text and business sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "negative_samples = reviews_merged_with_restauntants_with_30_to_200_reviews.loc[reviews_merged_with_restauntants_with_30_to_200_reviews['stars_x'] <2].sample(15000)\n",
    "positive_samples = reviews_merged_with_restauntants_with_30_to_200_reviews.loc[reviews_merged_with_restauntants_with_30_to_200_reviews['stars_x'] >4].sample(15000)\n",
    "selected_data = pd.concat([negative_samples, positive_samples])\n",
    "print(selected_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add(\"place\")\n",
    "stopwords.add(\"food\")\n",
    "stopwords.add(\"restaurant\")\n",
    "stopwords.add(\"order\")\n",
    "stopwords.add(\"pizza\")\n",
    "\n",
    "def generate_wordcloud(text):\n",
    "    wordcloud = WordCloud(background_color=\"white\", max_words=2000,\n",
    "                          stopwords = stopwords # set or space-separated string\n",
    "                          ).generate(text)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "positive  = \" \".join(train_data[train_labels == 1])\n",
    "generate_wordcloud(positive)\n",
    "\n",
    "negative  = \" \".join(train_data[train_labels == 0])\n",
    "generate_wordcloud(negative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
